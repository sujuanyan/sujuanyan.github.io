---
title: 'Paper Summary: Online Convex Programming and Generalized Infinitesimal Gradient Ascent'
date: 2021-01-25
permalink: /posts/2021/01/GIGA/
tags:
  - Online Optimization
  - paper summary
---
In this blog, I will give a summary of the paper ["Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. Proc. of ICML, 2003."](https://www.cs.cmu.edu/~maz/publications/techconvex.pdf) and talk about some of my understandings. To the best of my knowledge, this is the first paper that introduces the *online convex programming*, which is a generalization of the well-studied experts problem. Besides, A simple and natural method is proposed, namely the *generalized Infinitesimal Gradient Ascent (GIGA)*. This algorithm is straightforward but powerful with certain advantages. The paper first introduces the form online convex programming followed by a greedy projection algorithm. Then the GIGA method is proposed in the context of repeated games. The GIGA method is a generalized version of the algorithm *infinitesimal gradient ascent*, which is originally proposed for repeated games.

### 1. Online Convex Programming and Greedy Projection

In the traditional convex optimization problem, we want to find a decision variable inside a constraint set such that it suffers the minimum cost. Every parameters of the problem is given beforehand. However, in an *online convex programming problem*, we do not know the cost function until the decision is made. Mathematically, given a feasible set $F \subseteq \mathbb{R}^{n}$, at each time step $t$, an *onine convex programming algorithm* selects a vector $x^t \in F$, and then receives the cost function $c^t$. Note that the algorithm does not know what the cost function $c^t$ is before it makes the decision. 

Because an online algorithm does not have the full information, it will probably produce a sequence of $\{x^1,x^2,...\}$ that is not optimal. To measure the performance of an online algorithm, we compare it with the fixed optimal solution $x$ generated by an algorithm which knows all the cost functions beforehand. Mathematically, we define the regret of algorithm $A$ until time $T$:

$$
R_A(T) = \sum_{t=1}^T c^t(x^t) - \underset{x \in F}{\min} \sum_{t=1}^T C^t(x)
$$

Note that the "best solution" from the hindsight is a fixed vector independent of time $t$. Another possibility is to define regret against a dynamic strategy where the offline solution is allow a small number of change (c.f. section 2.2 of the original paper). 
An online algorithm $A$ is considered as a good algorithm if its average regret approaches zero, i.e. the regret $R_A(T)\sim o(T)$. Next, I will give the basic algorithm called *greedy projection* which indeed has a sub-linear regret.

### 2. The Algorithm

The greedy projection method is simple and natural. At first, it selects an arbitrary starting point $x^1$ inside the feasible set. At each iteration, it calculates the gradient of the cost function from the last step, performs a gradient descent with certain learning rate, and then projects the result back to the feasible set. Mathematically, it selects the vector $x^{t+1}$ according to:

$$
x^{t+1} = P(x^t-\eta_t(\nabla c^t(x^t)))
$$

where $\eta_t \in \mathbb{R}^{+}$ is the learning rate at each time step. The projection function 

$$P(y)=\arg \underset{x\in F}{\min} \|x-y\|$$ 

finds the closest vector to $y$ inside the feasible set. 

To analyze the regret of the greedy projection method, we first make the assumptions that the feasible set $F$ is bounded and there is an upper bound of the cost function gradients for all $t$ and $x\in F$. Formally, the diameter of the feasible set and the upper bound of the cost function gradients are given by 

$$||F|| = \underset{x,y\in F}{\max} ||x-y||$$ 

$$||\nabla c|| = \underset{x\in F, t\in \mathbb{N}}{sup}\; {||\nabla c^t(x)||}$$



$$
R_G(T) \leq \frac{\| F \|^2 \sqrt{T}}{2} + (\sqrt{T} - \frac{1}{2}) \|\nabla c \|^2
$$


